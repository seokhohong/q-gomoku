{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Convolution2D, Dense, Dropout, Flatten, concatenate, BatchNormalization\n",
    "from keras.models import Model  # basic class for specifying and training a neural network\n",
    "from keras import losses\n",
    "import keras\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz = np.load('models/train_vectors_13_13_r2.npz')\n",
    "train_vectors = npz['train_vectors']\n",
    "train_p = npz['train_p']\n",
    "train_q = npz['train_q']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(SIZE, SIZE, 1))\n",
    "\n",
    "bn1 = BatchNormalization()(inp)\n",
    "conv_1 = Convolution2D(64, (3, 3), padding='same', activation='relu',\n",
    "                       kernel_initializer='random_uniform')(bn1)\n",
    "bn2 = BatchNormalization()(conv_1)\n",
    "conv_2 = Convolution2D(64, (3, 3), padding='same', activation='relu',\n",
    "                       kernel_initializer='random_uniform')(bn2)\n",
    "bn3 = BatchNormalization()(conv_2)\n",
    "conv_3 = Convolution2D(64, (3, 3), padding='same', activation='relu',\n",
    "                       kernel_initializer='random_uniform')(bn3)\n",
    "bn4 = BatchNormalization()(conv_3)\n",
    "\n",
    "flat = Flatten()(bn4)\n",
    "turn_input = Input(shape=(1,), name='turn')\n",
    "full = concatenate([flat, turn_input])\n",
    "\n",
    "hidden = Dense(15, activation='relu', kernel_initializer='random_uniform')(full)\n",
    "bn4 = BatchNormalization()(hidden)\n",
    "\n",
    "out = Dense(1)(bn4)\n",
    "\n",
    "q_model = Model(inputs=[inp, turn_input], outputs=out)\n",
    "q_model.compile(loss=losses.mean_squared_error, optimizer='adam', metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "boards = np.array([board for board in train_vectors[:, 0]]).reshape(train_vectors.shape[0], SIZE, SIZE, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52358 samples, validate on 5818 samples\n",
      "Epoch 1/10\n",
      "52358/52358 [==============================] - 14s 259us/step - loss: 0.0181 - mean_squared_error: 0.0181 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "Epoch 2/10\n",
      "52358/52358 [==============================] - 13s 257us/step - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
      "Epoch 3/10\n",
      "52358/52358 [==============================] - 13s 256us/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0145 - val_mean_squared_error: 0.0145\n",
      "Epoch 4/10\n",
      "52358/52358 [==============================] - 13s 253us/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0094 - val_mean_squared_error: 0.0094\n",
      "Epoch 5/10\n",
      "52358/52358 [==============================] - 13s 255us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0095 - val_mean_squared_error: 0.0095\n",
      "Epoch 6/10\n",
      "52358/52358 [==============================] - 13s 257us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
      "Epoch 7/10\n",
      "52358/52358 [==============================] - 13s 256us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n",
      "Epoch 8/10\n",
      "52358/52358 [==============================] - 13s 254us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
      "Epoch 9/10\n",
      "52358/52358 [==============================] - 13s 252us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
      "Epoch 10/10\n",
      "52358/52358 [==============================] - 14s 258us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    model.fit([boards, \n",
    "               train_vectors[:, 1]], \n",
    "              train_q, \n",
    "              epochs=10,\n",
    "             validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/13_13_q_v2.net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(SIZE, SIZE, 1))\n",
    "\n",
    "bn1 = BatchNormalization()(inp)\n",
    "conv_1 = Convolution2D(64, (3, 3), padding='same', activation='relu',\n",
    "                       kernel_initializer='random_uniform')(bn1)\n",
    "bn2 = BatchNormalization()(conv_1)\n",
    "conv_2 = Convolution2D(64, (3, 3), padding='same', activation='relu',\n",
    "                       kernel_initializer='random_uniform')(bn2)\n",
    "bn3 = BatchNormalization()(conv_2)\n",
    "conv_3 = Convolution2D(64, (3, 3), padding='same', activation='relu',\n",
    "                       kernel_initializer='random_uniform')(bn3)\n",
    "bn4 = BatchNormalization()(conv_3)\n",
    "\n",
    "flat = Flatten()(bn4)\n",
    "turn_input = Input(shape=(1,), name='turn')\n",
    "full = concatenate([flat, turn_input])\n",
    "\n",
    "hidden = Dense(15, activation='relu', kernel_initializer='random_uniform')(full)\n",
    "bn4 = BatchNormalization()(hidden)\n",
    "\n",
    "out = Dense(SIZE ** 2, activation='softmax')(bn4)\n",
    "\n",
    "p_model = Model(inputs=[inp, turn_input], outputs=out)\n",
    "p_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52358 samples, validate on 5818 samples\n",
      "Epoch 1/10\n",
      "52358/52358 [==============================] - 15s 296us/step - loss: 3.9676 - acc: 0.1580 - val_loss: 3.2680 - val_acc: 0.2711\n",
      "Epoch 2/10\n",
      "52358/52358 [==============================] - 14s 269us/step - loss: 3.2059 - acc: 0.2865 - val_loss: 3.0075 - val_acc: 0.3118\n",
      "Epoch 3/10\n",
      "52358/52358 [==============================] - 14s 264us/step - loss: 2.9485 - acc: 0.3353 - val_loss: 2.8870 - val_acc: 0.3501\n",
      "Epoch 4/10\n",
      "52358/52358 [==============================] - 14s 260us/step - loss: 2.7680 - acc: 0.3700 - val_loss: 2.8445 - val_acc: 0.3781\n",
      "Epoch 5/10\n",
      "52358/52358 [==============================] - 14s 259us/step - loss: 2.6233 - acc: 0.3947 - val_loss: 2.8634 - val_acc: 0.3737\n",
      "Epoch 6/10\n",
      "52358/52358 [==============================] - 13s 254us/step - loss: 2.5032 - acc: 0.4145 - val_loss: 2.9012 - val_acc: 0.3805\n",
      "Epoch 7/10\n",
      "52358/52358 [==============================] - 13s 257us/step - loss: 2.4022 - acc: 0.4318 - val_loss: 2.8853 - val_acc: 0.3953\n",
      "Epoch 8/10\n",
      "52358/52358 [==============================] - 13s 257us/step - loss: 2.3062 - acc: 0.4518 - val_loss: 2.9672 - val_acc: 0.3783\n",
      "Epoch 9/10\n",
      "52358/52358 [==============================] - 13s 253us/step - loss: 2.2232 - acc: 0.4664 - val_loss: 2.9963 - val_acc: 0.3769\n",
      "Epoch 10/10\n",
      "52358/52358 [==============================] - 13s 244us/step - loss: 2.1460 - acc: 0.4828 - val_loss: 3.0761 - val_acc: 0.3733\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    p_model.fit([boards, \n",
    "               train_vectors[:, 1]], \n",
    "              train_p, \n",
    "              epochs=10,\n",
    "             validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_model.save('models/13_13_p_v2.net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
