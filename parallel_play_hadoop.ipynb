{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "from keras.layers import Input, Convolution2D, Dense, Dropout, Flatten, concatenate, BatchNormalization\n",
    "from keras.models import Model  # basic class for specifying and training a neural network\n",
    "from keras import losses\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from sortedcontainers import SortedSet\n",
    "\n",
    "import core\n",
    "import learner\n",
    "from learner.pexp_mind import PExpMind\n",
    "from core.board import Board\n",
    "from core import optimized_minimax\n",
    "import random\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "import cProfile\n",
    "\n",
    "random_state = np.random.RandomState(42)\n",
    "\n",
    "MIN_Q = -1\n",
    "MAX_Q = 1\n",
    "\n",
    "import importlib\n",
    "importlib.reload(learner.pexp_mind)\n",
    "importlib.reload(core.board)\n",
    "importlib.reload(core)\n",
    "importlib.reload(core.optimized_minimax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_imports():\n",
    "    import site\n",
    "    import core\n",
    "    import tensorflow\n",
    "    from core.board import Board\n",
    "    from learner.pexp_mind import PExpMind\n",
    "    return site.getsitepackages()\n",
    "\n",
    "sc.parallelize([1]).map(lambda x : test_imports()).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def any_p(depth, p):\n",
    "    return depth < np.inf\n",
    "\n",
    "def broad_p(depth, p):\n",
    "    return np.logical_or(np.logical_or(\n",
    "        np.logical_and(depth < 4, p > -7),\n",
    "        np.logical_and(depth < 6, p > -6),\n",
    "        np.logical_and(depth < 8, p > -6)),\n",
    "        np.logical_and(depth < np.inf, p > -5)\n",
    "    )\n",
    "\n",
    "def aggressive_p(depth, p):\n",
    "    return np.logical_or(np.logical_or(\n",
    "        np.logical_and(depth < 4, p > -5),\n",
    "        np.logical_and(depth < 6, p > -4),\n",
    "        np.logical_and(depth < 8, p > -4)),\n",
    "        np.logical_and(depth < np.inf, p > -3)\n",
    "    )\n",
    "\n",
    "def p_policy(i):\n",
    "    if i < 6:\n",
    "        return any_p\n",
    "    elif i < 15:\n",
    "        return broad_p\n",
    "    return aggressive_p\n",
    "\n",
    "def permissive_expansion(depth):\n",
    "    if depth < 2:\n",
    "        return np.inf\n",
    "    elif depth < 5:\n",
    "        return 20\n",
    "    elif depth < 8:\n",
    "        return 5\n",
    "    return 3\n",
    "\n",
    "def narrow_expansion(depth):\n",
    "    if depth < 2:\n",
    "        return np.inf\n",
    "    if depth < 8:\n",
    "        return 5\n",
    "    return 3\n",
    "\n",
    "def expansion_policy(i):\n",
    "    if i < 6:\n",
    "        return permissive_expansion\n",
    "    return narrow_expansion\n",
    "\n",
    "def init_random_board():\n",
    "    good_board = False\n",
    "    while not good_board:\n",
    "        round_board = Board(size=SIZE, win_chain_length=WIN_CHAIN_LENGTH)\n",
    "        \n",
    "        # randomize the board a bit\n",
    "        for j in range(random.randint(0, int(SIZE * 2.5))):\n",
    "            round_board.make_random_move()\n",
    "            if round_board.game_over():\n",
    "                break\n",
    "                \n",
    "        if not round_board.game_over():\n",
    "            good_board = True\n",
    "                \n",
    "    return round_board\n",
    "    \n",
    "def play_a_game(i):\n",
    "    \n",
    "    mind = PExpMind(size=SIZE, init=False, channels=CHANNELS)\n",
    "    \n",
    "    mind.define_policies(p_policy(i), expansion_policy(i), \n",
    "                         alpha=ALPHA, q_exp_batch_size=SIZE ** 2,\n",
    "                        convergence_count=convergence_function(i),\n",
    "                        required_depth=req_depth_function(i),\n",
    "                        p_exp_batch_size=k_function(i),\n",
    "                        max_iters=max_iter_function(i))\n",
    "    \n",
    "    mind.value_est.set_weights(q_model_bc.value)\n",
    "    mind.policy_est.set_weights(p_model_bc.value)\n",
    "    \n",
    "    round_board = init_random_board()\n",
    "    \n",
    "    current_player = round_board.player_to_move\n",
    "    while True:\n",
    "        result = mind.make_move(round_board,\n",
    "                                as_player=current_player,\n",
    "                                epsilon=0.05)\n",
    "        print(round_board.pprint())\n",
    "        if current_player == Board.FIRST_PLAYER:\n",
    "            current_player = Board.SECOND_PLAYER\n",
    "        else:\n",
    "            current_player = Board.FIRST_PLAYER\n",
    "        if result:\n",
    "            break\n",
    "            \n",
    "    return mind.train_vectors, mind.train_p, mind.train_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def convergence_function(i):\n",
    "    if i < 2:\n",
    "        return 1\n",
    "    if i < 5:\n",
    "        return 3\n",
    "    return 5\n",
    "\n",
    "def max_iter_function(i):\n",
    "    # the first iteration has to teach the model that most positions aren't game ending\n",
    "    if i == 0:\n",
    "        return 1\n",
    "    if i < 2:\n",
    "        return 5\n",
    "    if i < 4:\n",
    "        return 10\n",
    "    if i < 7:\n",
    "        return 15\n",
    "    if i < 10: # after 10, increase K\n",
    "        return 20\n",
    "    if i < 15:\n",
    "        return 10\n",
    "    if i < 20:\n",
    "        return 15\n",
    "    return 25\n",
    "\n",
    "def k_function(i):\n",
    "    if i < 10:\n",
    "        return SIZE ** 2\n",
    "    return SIZE ** 3\n",
    "\n",
    "def req_depth_function(i):\n",
    "    if i == 0:\n",
    "        return 1\n",
    "    if i < 2:\n",
    "        return 2\n",
    "    if i < 4:\n",
    "        return 3\n",
    "    if i < 8:\n",
    "        return 4\n",
    "    if i < 12:\n",
    "        return 5\n",
    "    return 6\n",
    "    \n",
    "def wait_until_exists(file_path):\n",
    "    while not os.path.exists(file_path):\n",
    "        time.sleep(1)\n",
    "\n",
    "    if os.path.isfile(file_path):\n",
    "        return True\n",
    "    else:\n",
    "        raise ValueError(\"%s isn't a file!\" % file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SIZE = 9\n",
    "WIN_CHAIN_LENGTH = 5\n",
    "CHANNELS = 4\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "GAME_BATCH = 1000\n",
    "ALPHA = 0.2\n",
    "\n",
    "VECTORS_NPZ = 'gomoku/models/waiting_vectors.npz'\n",
    "VECTORS_COMPLETE = 'gomoku/models/waiting_vectors_complete'\n",
    "P_MODEL = \"gomoku/models/waiting_p.model\"\n",
    "Q_MODEL = \"gomoku/models/waiting_q.model\"\n",
    "MODEL_COMPLETE = 'gomoku/models/waiting_models_complete'\n",
    "\n",
    "PATIENCE = 3\n",
    "\n",
    "def load_models(mind):\n",
    "    if 'value_est' in mind.__dict__:\n",
    "        del mind.value_est\n",
    "        del mind.policy_est\n",
    "    \n",
    "    try:\n",
    "        mind.value_est = keras.models.load_model(Q_MODEL)\n",
    "        mind.policy_est = keras.models.load_model(P_MODEL)\n",
    "    except:\n",
    "        mind.value_est = keras.models.load_model(Q_MODEL)\n",
    "        mind.policy_est = keras.models.load_model(P_MODEL)        \n",
    "    \n",
    "def save_models(mind):\n",
    "    mind.value_est.save(Q_MODEL)\n",
    "    mind.policy_est.save(P_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "load = True\n",
    "\n",
    "mind = PExpMind(size=SIZE, init=not load, channels=CHANNELS)\n",
    "\n",
    "if load:\n",
    "    load_models(mind)\n",
    "else:\n",
    "    save_models(mind)\n",
    "    \n",
    "q_model_bc = sc.broadcast(mind.value_est.get_weights())\n",
    "p_model_bc = sc.broadcast(mind.policy_est.get_weights())\n",
    "\n",
    "def distributed_play(i):\n",
    "    \n",
    "    collected = sc.parallelize(zip(range(GAME_BATCH), range(GAME_BATCH))).partitionBy(GAME_BATCH, lambda x: x) \\\n",
    "                    .map(lambda x : play_a_game(i)).collect()\n",
    "        \n",
    "    if collected is None:\n",
    "        collected = sc.parallelize(zip(range(GAME_BATCH), range(GAME_BATCH))).partitionBy(GAME_BATCH, lambda x: x) \\\n",
    "                    .map(lambda x : play_a_game(i)).collect()\n",
    "\n",
    "    all_vectors = []\n",
    "    all_p = []\n",
    "    all_q = []\n",
    "\n",
    "    train_q_vectors = []\n",
    "    train_p_vectors = []\n",
    "    train_p = []\n",
    "    train_q = []\n",
    "\n",
    "    for vectors, p, q in collected:\n",
    "        all_vectors.extend(vectors)\n",
    "        all_p.extend(p)\n",
    "        all_q.extend(q)\n",
    "\n",
    "    for vector, p, q in zip(all_vectors, all_p, all_q):\n",
    "        train_q_vectors.append(vector)\n",
    "        if optimized_minimax.PExpNode.is_result_q(q) or i > 0:\n",
    "            train_q.append(q)\n",
    "        else:\n",
    "            train_q.append(0)\n",
    "\n",
    "        if abs(q) > 0:\n",
    "            train_p_vectors.append(vector)\n",
    "            train_p.append(p)\n",
    "\n",
    "    print(train_q[:100])\n",
    "\n",
    "    np.savez(VECTORS_NPZ, \n",
    "             train_p_vectors = train_p_vectors,\n",
    "             train_q_vectors = train_q_vectors, \n",
    "             train_p=train_p, \n",
    "             train_q=train_q)\n",
    "    \n",
    "    with open(VECTORS_COMPLETE, 'w') as f:\n",
    "        f.write('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 5000\n",
    "start_at = 11\n",
    "\n",
    "for i in range(start_at, epochs):\n",
    "    if i > 0:\n",
    "        if wait_until_exists(MODEL_COMPLETE):\n",
    "            print(\"Models Completed!\")\n",
    "            load_models(mind)\n",
    "            q_model_bc = sc.broadcast(mind.value_est.get_weights())\n",
    "            p_model_bc = sc.broadcast(mind.policy_est.get_weights())\n",
    "            print('Models Loaded')\n",
    "            \n",
    "    distributed_play(i)\n",
    "    \n",
    "    if i > 0:\n",
    "        os.remove(MODEL_COMPLETE)\n",
    "    \n",
    "    print(\"Completed Simulations\")\n",
    "    \n",
    "    play_a_game(i)\n",
    "    \n",
    "    if i % 5 == 0 and i > 0:\n",
    "        load_models(mind)\n",
    "        mind.save('gomoku/models/9_channel4_exp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q_model_bc = sc.broadcast(copy.deepcopy(q_model.get_weights()))\n",
    "p_model_bc = sc.broadcast(copy.deepcopy(p_model.get_weights()))\n",
    "collected = sc.parallelize(zip(range(1000), range(1000))).partitionBy(1000, lambda x: x) \\\n",
    "                .map(lambda x : play_a_game(15)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_vectors = []\n",
    "all_p = []\n",
    "all_q = []\n",
    "\n",
    "train_q_vectors = []\n",
    "train_p_vectors = []\n",
    "train_p = []\n",
    "train_q = []\n",
    "\n",
    "i=0\n",
    "for vectors, p, q in collected:\n",
    "    all_vectors.extend(vectors)\n",
    "    all_p.extend(p)\n",
    "    all_q.extend(q)\n",
    "\n",
    "for vector, p, q in zip(all_vectors, all_p, all_q):\n",
    "    train_q_vectors.append(vector)\n",
    "    if optimized_minimax.PExpNode.is_result_q(q) or i > 0:\n",
    "        train_q.append(q)\n",
    "    else:\n",
    "        train_q.append(0)\n",
    "\n",
    "    if abs(q) > 0:\n",
    "        train_p_vectors.append(vector)\n",
    "        train_p.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(train_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q_model.fit(x=fit_train_inputs,\n",
    "                    y=np.array(fit_train_q),\n",
    "                    shuffle=True,\n",
    "                    callbacks=[EarlyStopping(patience=PATIENCE)],\n",
    "                    validation_data = (fit_valid_inputs, fit_valid_q),\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "play_a_game(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savez('gomoku/models/7_4channel.npz', train_q_vectors=train_q_vectors, train_p_vectors=train_p_vectors,\n",
    "         train_p=train_p, train_q=train_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_inputs = []\n",
    "for vector, whose_move in train_vectors:\n",
    "    train_inputs.append(vector.reshape(SIZE, SIZE, CHANNELS))\n",
    "\n",
    "train_inputs = np.array(train_inputs)\n",
    "\n",
    "fraction = 0.9\n",
    "fit_train_inputs = train_inputs[:int(len(train_inputs) * fraction)]\n",
    "fit_train_q = train_q[:int(len(train_inputs) * fraction)]\n",
    "fit_train_p = np.array(train_p[:int(len(train_inputs) * fraction)]).reshape(-1, SIZE ** 2)\n",
    "\n",
    "fit_valid_inputs = train_inputs[int(len(train_inputs) * fraction):]\n",
    "fit_valid_q = train_q[int(len(train_inputs) * fraction):]\n",
    "fit_valid_p = np.array(train_p[int(len(train_inputs) * fraction):]).reshape(-1, SIZE ** 2)\n",
    "\n",
    "if len(train_vectors) > 0:\n",
    "    q_model.fit(x=fit_train_inputs,\n",
    "                y=np.array(fit_train_q),\n",
    "                shuffle=True,\n",
    "                callbacks=[EarlyStopping(patience=PATIENCE)],\n",
    "                validation_data = (fit_valid_inputs, fit_valid_q),\n",
    "                batch_size=BATCH_SIZE,\n",
    "                epochs=EPOCHS)\n",
    "    # doesn't always need to train P\n",
    "    if max_iter_function(i) > 2:\n",
    "        p_model.fit(x=fit_train_inputs,\n",
    "                    y=np.array(fit_train_p),\n",
    "                    shuffle=True,\n",
    "                    callbacks=[EarlyStopping(patience=PATIENCE)],\n",
    "                    validation_data = (fit_valid_inputs, fit_valid_p),\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [hseokho.q-gomoku]",
   "language": "python",
   "name": "hseokho.q-gomoku"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}