{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/dslab/anaconda/python3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Convolution2D, Dense, Dropout, Flatten, concatenate, BatchNormalization\n",
    "from keras.models import Model  # basic class for specifying and training a neural network\n",
    "from keras import losses\n",
    "import keras\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz = np.load('models/train_vectors_9_9_r1.npz')\n",
    "train_vectors = npz['train_vectors']\n",
    "train_p = npz['train_p']\n",
    "train_q = npz['train_q']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(SIZE, SIZE, 1))\n",
    "\n",
    "bn1 = BatchNormalization()(inp)\n",
    "conv_1 = Convolution2D(64, (3, 3), padding='valid', activation='relu',\n",
    "                       kernel_initializer='random_uniform')(bn1)\n",
    "bn2 = BatchNormalization()(conv_1)\n",
    "conv_2 = Convolution2D(64, (3, 3), padding='valid', activation='relu',\n",
    "                       kernel_initializer='random_uniform')(bn2)\n",
    "bn3 = BatchNormalization()(conv_2)\n",
    "conv_3 = Convolution2D(64, (3, 3), padding='valid', activation='relu',\n",
    "                       kernel_initializer='random_uniform')(bn3)\n",
    "bn4 = BatchNormalization()(conv_3)\n",
    "\n",
    "flat = Flatten()(bn4)\n",
    "turn_input = Input(shape=(1,), name='turn')\n",
    "full = concatenate([flat, turn_input])\n",
    "\n",
    "hidden = Dense(15, activation='relu', kernel_initializer='random_uniform')(full)\n",
    "bn4 = BatchNormalization()(hidden)\n",
    "\n",
    "out = Dense(1)(bn4)\n",
    "\n",
    "q_model = Model(inputs=[inp, turn_input], outputs=out)\n",
    "q_model.compile(loss=losses.mean_squared_error, optimizer='adam', metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "boards = np.array([board for board in train_vectors[:, 0]]).reshape(train_vectors.shape[0], SIZE, SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 89924 samples, validate on 9992 samples\n",
      "Epoch 1/10\n",
      "89924/89924 [==============================] - 23s 255us/step - loss: 0.0847 - mean_squared_error: 0.0847 - val_loss: 0.0572 - val_mean_squared_error: 0.0572\n",
      "Epoch 2/10\n",
      "89924/89924 [==============================] - 21s 228us/step - loss: 0.0401 - mean_squared_error: 0.0401 - val_loss: 0.0355 - val_mean_squared_error: 0.0355\n",
      "Epoch 3/10\n",
      "89924/89924 [==============================] - 20s 227us/step - loss: 0.0320 - mean_squared_error: 0.0320 - val_loss: 0.0321 - val_mean_squared_error: 0.0321\n",
      "Epoch 4/10\n",
      "89924/89924 [==============================] - 21s 229us/step - loss: 0.0274 - mean_squared_error: 0.0274 - val_loss: 0.0255 - val_mean_squared_error: 0.0255\n",
      "Epoch 5/10\n",
      "89924/89924 [==============================] - 20s 227us/step - loss: 0.0250 - mean_squared_error: 0.0250 - val_loss: 0.0261 - val_mean_squared_error: 0.0261\n",
      "Epoch 6/10\n",
      "89924/89924 [==============================] - 20s 223us/step - loss: 0.0233 - mean_squared_error: 0.0233 - val_loss: 0.0234 - val_mean_squared_error: 0.0234\n",
      "Epoch 7/10\n",
      "65632/89924 [====================>.........] - ETA: 5s - loss: 0.0217 - mean_squared_error: 0.0217"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    q_model.fit([boards, \n",
    "               train_vectors[:, 1]], \n",
    "              train_q, \n",
    "              epochs=10,\n",
    "             validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_model.save('models/13_13_q_v3.net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(SIZE, SIZE, 1))\n",
    "\n",
    "bn1 = BatchNormalization()(inp)\n",
    "conv_1 = Convolution2D(64, (3, 3), padding='same', activation='relu',\n",
    "                       kernel_initializer='random_uniform')(bn1)\n",
    "bn2 = BatchNormalization()(conv_1)\n",
    "conv_2 = Convolution2D(64, (3, 3), padding='same', activation='relu',\n",
    "                       kernel_initializer='random_uniform')(bn2)\n",
    "bn3 = BatchNormalization()(conv_2)\n",
    "conv_3 = Convolution2D(64, (3, 3), padding='same', activation='relu',\n",
    "                       kernel_initializer='random_uniform')(bn3)\n",
    "bn4 = BatchNormalization()(conv_3)\n",
    "#conv_4 = Convolution2D(64, (3, 3), padding='same', activation='relu',\n",
    "#                       kernel_initializer='random_uniform')(bn4)\n",
    "#bn5 = BatchNormalization()(conv_4)\n",
    "#conv_5 = Convolution2D(64, (3, 3), padding='same', activation='relu',\n",
    "#                       kernel_initializer='random_uniform')(bn5)\n",
    "#bn6 = BatchNormalization()(conv_5)\n",
    "\n",
    "flat = Flatten()(bn4)\n",
    "turn_input = Input(shape=(1,), name='turn')\n",
    "full = concatenate([flat, turn_input])\n",
    "\n",
    "hidden = Dense(15, activation='relu', kernel_initializer='random_uniform')(full)\n",
    "bn4 = BatchNormalization()(hidden)\n",
    "\n",
    "out = Dense(SIZE ** 2, activation='softmax')(bn4)\n",
    "\n",
    "p_model = Model(inputs=[inp, turn_input], outputs=out)\n",
    "p_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 58464 samples, validate on 6496 samples\n",
      "Epoch 1/3\n",
      "58464/58464 [==============================] - 15s 256us/step - loss: 4.5833 - acc: 0.1080 - val_loss: 4.3583 - val_acc: 0.1404\n",
      "Epoch 2/3\n",
      "58464/58464 [==============================] - 13s 219us/step - loss: 4.1298 - acc: 0.1903 - val_loss: 4.2087 - val_acc: 0.1809\n",
      "Epoch 3/3\n",
      "58464/58464 [==============================] - 12s 213us/step - loss: 3.9583 - acc: 0.2184 - val_loss: 4.1568 - val_acc: 0.1940\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    p_model.fit([boards, \n",
    "               train_vectors[:, 1]], \n",
    "              train_p, \n",
    "              epochs=3,\n",
    "             validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_model.save('models/13_13_p_v2.net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
