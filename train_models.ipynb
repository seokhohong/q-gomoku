{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Convolution2D, Dense, Dropout, Flatten, concatenate, BatchNormalization\n",
    "from keras.models import Model  # basic class for specifying and training a neural network\n",
    "from keras import losses\n",
    "import keras\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SIZE = 7\n",
    "CHANNELS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "npz = np.load('gomoku/models/7_20channel.npz')\n",
    "train_inputs = npz['train_inputs']\n",
    "train_p = npz['train_p']\n",
    "train_q = npz['train_q']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(SIZE, SIZE, CHANNELS))\n",
    "\n",
    "# key difference between this and conv network is padding\n",
    "conv_1 = Convolution2D(32, (2, 2), padding='valid', activation='relu',\n",
    "                       kernel_initializer='random_normal', use_bias=False)(inp)\n",
    "bn2 = BatchNormalization()(conv_1)\n",
    "conv_2 = Convolution2D(16, (3, 3), padding='valid', activation='relu',\n",
    "                       kernel_initializer='random_normal', use_bias=False)(bn2)\n",
    "bn3 = BatchNormalization()(conv_2)\n",
    "#conv_3 = Convolution2D(32, (3, 3), padding='valid', activation='relu',\n",
    "#                       kernel_initializer='random_normal', use_bias=False)(bn3)\n",
    "#bn4 = BatchNormalization()(conv_3)\n",
    "#conv_4 = Convolution2D(16, (3, 3), padding='valid', activation='relu',\n",
    "#                       kernel_initializer='random_normal', use_bias=False)(bn4)\n",
    "#bn5 = BatchNormalization()(conv_4)\n",
    "\n",
    "flat = Flatten()(bn3)\n",
    "\n",
    "hidden = Dense(10, activation='relu', kernel_initializer='random_normal', use_bias=False)(flat)\n",
    "bn_final = BatchNormalization()(hidden)\n",
    "\n",
    "out = Dense(1, use_bias=False)(bn_final)\n",
    "\n",
    "q_model = Model(inputs=[inp], outputs=out)\n",
    "q_model.compile(loss=losses.mean_squared_error, optimizer='adam', metrics=['mean_squared_error'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(SIZE, SIZE, CHANNELS))\n",
    "\n",
    "# key difference between this and conv network is padding\n",
    "conv_1 = Convolution2D(64, (3, 3), padding='same', activation='relu',\n",
    "                       kernel_initializer='random_normal', use_bias=False)(inp)\n",
    "bn2 = BatchNormalization()(conv_1)\n",
    "conv_2 = Convolution2D(32, (3, 3), padding='same', activation='relu',\n",
    "                       kernel_initializer='random_normal', use_bias=False)(bn2)\n",
    "bn3 = BatchNormalization()(conv_2)\n",
    "conv_3 = Convolution2D(32, (3, 3), padding='valid', activation='relu',\n",
    "                       kernel_initializer='random_normal', use_bias=False)(bn3)\n",
    "bn4 = BatchNormalization()(conv_3)\n",
    "#conv_4 = Convolution2D(16, (3, 3), padding='valid', activation='relu',\n",
    "#                       kernel_initializer='random_normal', use_bias=False)(bn4)\n",
    "#bn5 = BatchNormalization()(conv_4)\n",
    "\n",
    "flat = Flatten()(bn4)\n",
    "\n",
    "hidden = Dense(10, activation='relu', kernel_initializer='random_normal', use_bias=False)(flat)\n",
    "bn_final = BatchNormalization()(hidden)\n",
    "\n",
    "out = Dense(1, use_bias=False)(bn_final)\n",
    "\n",
    "q_model = Model(inputs=[inp], outputs=out)\n",
    "q_model.compile(loss=losses.mean_squared_error, optimizer='adam', metrics=['mean_squared_error'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fraction = 0.9\n",
    "fit_train_inputs = train_inputs[:int(len(train_inputs) * fraction)]\n",
    "fit_train_q = train_q[:int(len(train_inputs) * fraction)]\n",
    "\n",
    "fit_valid_inputs = train_inputs[int(len(train_inputs) * fraction):]\n",
    "fit_valid_q = train_q[int(len(train_inputs) * fraction):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_model.fit(fit_train_inputs, \n",
    "                fit_train_q, \n",
    "                shuffle=True,\n",
    "              epochs=100,\n",
    "             validation_data=(fit_valid_inputs, fit_valid_q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q_model.save('models/batch_9_9_q_v3_5.net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(SIZE, SIZE, 1))\n",
    "\n",
    "bn1 = BatchNormalization()(inp)\n",
    "conv_1 = Convolution2D(64, (5, 5), padding='same', activation='relu',\n",
    "                       kernel_initializer='random_uniform')(bn1)\n",
    "bn2 = BatchNormalization()(conv_1)\n",
    "conv_2 = Convolution2D(64, (3, 3), padding='same', activation='relu',\n",
    "                       kernel_initializer='random_uniform')(bn2)\n",
    "bn3 = BatchNormalization()(conv_2)\n",
    "conv_3 = Convolution2D(64, (3, 3), padding='valid', activation='relu',\n",
    "                       kernel_initializer='random_uniform')(bn3)\n",
    "bn4 = BatchNormalization()(conv_3)\n",
    "#conv_4 = Convolution2D(64, (3, 3), padding='same', activation='relu',\n",
    "#                       kernel_initializer='random_uniform')(bn4)\n",
    "#bn5 = BatchNormalization()(conv_4)\n",
    "#conv_5 = Convolution2D(64, (3, 3), padding='same', activation='relu',\n",
    "#                       kernel_initializer='random_uniform')(bn5)\n",
    "#bn6 = BatchNormalization()(conv_5)\n",
    "\n",
    "flat = Flatten()(bn4)\n",
    "turn_input = Input(shape=(1,), name='turn')\n",
    "full = concatenate([flat, turn_input])\n",
    "\n",
    "hidden = Dense(15, activation='relu', kernel_initializer='random_uniform')(full)\n",
    "bn4 = BatchNormalization()(hidden)\n",
    "\n",
    "out = Dense(SIZE ** 2, activation='softmax')(bn4)\n",
    "\n",
    "p_model = Model(inputs=[inp, turn_input], outputs=out)\n",
    "p_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    p_model.fit([boards, \n",
    "               train_vectors[:, 1]], \n",
    "              train_p, \n",
    "              epochs=5,\n",
    "             validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_model.save('models/9_9_p_v2_2.net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}